{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMoIktzGVRzZO2iro6ZuDI+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Nan_euclidean distance\n","When calculating the distance between a pair of samples, this formulation ignores feature coordinates with a missing value in either sample and scales up the weight of the remaining coordinates:\n","\n","How to find the distance between two points when some values are NaN ?\n","\n","|Rows|col0|col1|col2|col3|\n","|-|-|-|-|-|\n","|r0|$X_{00}$|$X_{01}$|$X_{02}$|$X_{03}$|$X_{04}$|\n","|r1|$X_{10}$|$X_{11}$|$X_{12}$|$X_{13}$|\n","|r2|$X_{20}$|$X_{21}$|$X_{22}$|$X_{23}$|\n","|r3|$X_{30}$|$X_{31}$|$X_{32}$|$X_{33}$|\n","\n","\\\n","\n","||col1|col2|col3|col4|\n","|-|-|-|-|-|\n","|r0|3|np.nan| 2| 0|\n","|r1|5| 4| 1| 5|\n","|r2|6| 7| 7| 5|\n","|r3|6| 5| 4| np.nan|\n","\n","$ \\verb|weight| = \\dfrac{\\verb|Total number of columns|}{\\verb|number of columns with values present in row0 and row3|} $\n","\n","$\\verb|dist( r0,r3)| = \\sqrt{\\verb|weight| *[(X_{00}- X_{30})^2+ (X_{02}- X_{32})^2]} $         \n","\n","\n","\\\n","\\\n","example,\n","## Find the nan_euclidean distance between point1 $\\verb|[3, np.nan,2, 0]|$ and point2 $\\verb|[6,5,4, np.nan]|$?\n","\n","If I ignore the values which have nan values then,\n","Euclidean Distances = $\\sqrt{(3-6)^2+ (2-4)^2} = \\sqrt{9 + 4} = 3.605 $\n","\n","$Weight = \\dfrac{4}{2} = 2 $\\\n","$\\verb|dist (row0 and row3|)  = \\sqrt{2*[(3-6)^2+ (2-4)^2]} = \\sqrt{2*[9+4]} = \\sqrt{26} \\approx 5.099$\n","\n","\\\\\n","\n","## Find the nan_euclidean distance between point1 $\\verb|[3, np.nan,2, 0]|$ and point2 $\\verb|[5,4,1,5]|$?\n","\n","$Weight = \\dfrac{4}{3} $\\\n","$\\verb|dist (row0 and row1|)  = \\sqrt{\\dfrac{4}{3}*[(3-5)^2+ (2-1)^2 + (0-5)^2]} = \\sqrt{\\dfrac{4}{3}*[4+1+25]} = \\sqrt{40} \\approx 6.324$\n","\n"],"metadata":{"id":"Sm9fC4PLLg-i"}},{"cell_type":"code","source":["from sklearn.metrics.pairwise import nan_euclidean_distances\n","import numpy as np\n","\n","X = np.array([[3, np.nan, 2, 0],\n","              [5, 4, 1, 5],\n","              [6, 7, 7, 5],\n","              [6, 5, 4, np.nan]])\n","nan_euclidean_distances(X[[0]], X[[3]]) #distance between rows of X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaUnDjnsPwl5","executionInfo":{"status":"ok","timestamp":1722605833007,"user_tz":-330,"elapsed":1078,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"10a7887e-ef6d-4944-8d51-3c7a844f9a21"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.09901951]])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["nan_euclidean_distances(X[[0]], X[[1]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZIlwCqqSul4","executionInfo":{"status":"ok","timestamp":1722605839455,"user_tz":-330,"elapsed":392,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"bc6ba27d-2d19-4ebc-adab-44c525d36272"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6.32455532]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["nan_euclidean_distances(X, X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-zTWj4iSyDS","executionInfo":{"status":"ok","timestamp":1700560320903,"user_tz":-330,"elapsed":3,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"34779b20-a685-49e1-86be-38b3e5cc2b3d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 6.32455532, 5.09901951, 8.86942313],\n","       [6.32455532, 0.        , 3.82970843, 6.78232998],\n","       [5.09901951, 3.82970843, 0.        , 4.163332  ],\n","       [8.86942313, 6.78232998, 4.163332  , 0.        ]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["How to impute values using neighbors values ?\n","- KNNImputer(n_neighbors=2, weights=\"uniform\") \\\n","  - choose 2 nearest neighbors and take mean value of that.\n","  - Note while taking mean we say all values have uniform weight.\n","$X_{01} = \\dfrac{(X_{11} + X_{21})}{2}$\n","\n","    W_1 = 1 \\\n","    W_2 = 1 \\\n","  $X_{01} = \\dfrac{(W_1 * X_{11} + W_2 *X_{21})}{(W_1 + W_2)}$\n","\n","but what happens if weights($W_1, W_2$) is not uniform but based on distance.\n","\n","- KNNImputer(n_neighbors=2, weights=\"distance\")\n","  - weight points by the inverse of their distance. in this case,closer neighbors of a query point will have a greater influence than neighbors which are further away.\n","\n","  w1 = (1/6.32) \\\n","  w2 = (1/5.099) \\\n","  \n","  $X_{01} = \\dfrac{(W_1 * X_{11} + W_2 *X_{21})}{(W_1 + W_2)}$\n","  \n","  $ \\dfrac{(4*w1) + (5*w2)}{(w1+w2} = 4.553 $\n","\n"],"metadata":{"id":"CKLyBrfjT-Sq"}},{"cell_type":"code","source":["#@title KNNImputer(n_neighbors=2, weights=\"uniform\")\n","\n","import numpy as np\n","from sklearn.impute import KNNImputer\n","X = np.array([[3, np.nan, 2, 0],\n","              [5, 4, 1, 5],\n","              [6, 5, 4, np.nan],\n","              [6, 7, 7, 5]])\n","\n","imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n","# Note weights parameter given here is completely different from the weight we defined for nan_euclidean distances.\n","\n","imputer.fit_transform(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcVhKPNUS6Lh","executionInfo":{"status":"ok","timestamp":1700561422730,"user_tz":-330,"elapsed":480,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"ed1b0889-9518-4594-a4ab-6fb9416451b2","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3. , 4.5, 2. , 0. ],\n","       [5. , 4. , 1. , 5. ],\n","       [6. , 5. , 4. , 5. ],\n","       [6. , 7. , 7. , 5. ]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#@title KNNImputer(n_neighbors=2, weights=\"distance\")\n","import numpy as np\n","from sklearn.impute import KNNImputer\n","X = np.array([[3, np.nan, 2, 0],\n","              [5, 4, 1, 5],\n","              [6, 5, 4, np.nan],\n","              [6, 7, 7, 5]])\n","\n","imputer = KNNImputer(n_neighbors=2, weights=\"distance\")\n","# \"distance\" : weight points by the inverse of their distance. in this case,\n","#closer neighbors of a query point will have a greater influence than\n","#neighbors which are further away.\n","imputer.fit_transform(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xlG4gb6TSAf","executionInfo":{"status":"ok","timestamp":1700561504047,"user_tz":-330,"elapsed":350,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"802ee17b-75a7-43e8-b6e9-beb437764bec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3.        , 4.55364064, 2.        , 0.        ],\n","       [5.        , 4.        , 1.        , 5.        ],\n","       [6.        , 5.        , 4.        , 5.        ],\n","       [6.        , 7.        , 7.        , 5.        ]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# NearestNeighbors\n","KneighborsClassifier uses NearestNeighbors function to compute distances\n"],"metadata":{"id":"f0-2bJeHLPE9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3RuDWysJ-Q_","executionInfo":{"status":"ok","timestamp":1710513918112,"user_tz":-330,"elapsed":1781,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"14258787-771d-4e3b-bec4-50eeae129576"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.3        0.7        1.64012195]]\n","[[2 0 1]]\n"]}],"source":["#@title Que : Find the distance of datapoint= [[0, 0, 1.3]] from all the datapoints in X.\n","import numpy as np\n","from sklearn.neighbors import NearestNeighbors\n","datapoint = [[0, 0, 1.3]]\n","\n","X = [[0, 0, 2],\n","    [1, 0, 0],\n","    [0, 0, 1]]\n","\n","neigh = NearestNeighbors(n_neighbors=2, radius=0.4,metric=\"euclidean\")\n","neigh.fit(X)\n","distances, indices = neigh.kneighbors(datapoint , n_neighbors = 3)\n","print(distances)\n","print(indices)"]},{"cell_type":"markdown","source":["# KNN\n","\n","- It is a non parametric algorithm\n","- = It is a supervised ML algorithm\n","- K = Number of neighbour considered for voting (n_neighbors)\n","- How to decide the label of unknown datapoints?\n","  - mean values of neighbor in Regression.\n","  - Voting majority class of neighbors in Classification\n","\n","- As K increases model will underfit and it will form smooth decision boundaries.\n","\n","- As K decreases model will overfit and it will form complex decision boundaries\n","\n","- We can't create groups if labels are not known.\n","\n","- Do scaling before model fitting because internally it calculates distance between two points.  \n"],"metadata":{"id":"bIykRfGlJ_Sl"}},{"cell_type":"markdown","source":["## Issues with knn\n","- Compute distance of every point\n","- Prediction is computationally expensive\n","- No model is learnt  \n","- Algorithm have to remember all the points for predicting new datapoints.\n"],"metadata":{"id":"8z4zG9MBLBdn"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","X_train = [[1,100],[4,400],[5,500],[6,600],[8,800],[9,900],[11,1100],[12,1200], [15,1500], [18,1800],[19,1900]]\n","y_train = [0,0,1,1,1,2,2,2,2,2,2]\n","\n","X_test = [[2,200]]\n","\n","knn = KNeighborsClassifier(n_neighbors= 3, metric=\"euclidean\",weights= 'uniform')\n","knn.fit(X_train,y_train)\n","\n","print(knn.predict(X_test))"],"metadata":{"id":"Zgmedsh7Z_f_","executionInfo":{"status":"ok","timestamp":1710513925053,"user_tz":-330,"elapsed":418,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"ed5414ef-577a-45cb-b267-cf9e7ebdadf0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0]\n"]}]},{"cell_type":"code","source":["knn.kneighbors([[1,100]]) # finding the neighbors of the first training point"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HksfQjZk94p","executionInfo":{"status":"ok","timestamp":1710514064464,"user_tz":-330,"elapsed":27,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"54d4632c-c379-492f-fdf6-b7ea3446bdf4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[  0.        , 300.01499963, 400.0199995 ]]), array([[0, 1, 2]]))"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","X_train = [[1,100],[4,400],[5,500],[6,600],[8,800],[9,900],[11,1100],[12,1200], [15,1500], [18,1800],[19,1900]]\n","y_train = [0,0,1,1,1,2,2,2,2,2,2]\n","\n","X_test = [[2,200]]\n","\n","knn = KNeighborsClassifier(n_neighbors= len(y_train), metric=\"euclidean\",weights= 'uniform')\n","knn.fit(X_train,y_train)\n","\n","print(knn.predict(X_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AoMSdTzsYIZY","executionInfo":{"status":"ok","timestamp":1700562219577,"user_tz":-330,"elapsed":530,"user":{"displayName":"22t1 cs2008","userId":"04624352279315398013"}},"outputId":"efd7039c-e875-4b90-ec33-b14d42359dbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2]\n"]}]}]}