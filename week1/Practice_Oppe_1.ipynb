{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhLoie7VKqUy"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YVDPF_SKyQU"
      },
      "source": [
        "### Access the dataset from here :\n",
        "\n",
        "https://drive.google.com/file/d/1XztaPmhMMhBoEp7XuyDGS5Il_kLUlEEl/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwkYDkX3uuR7"
      },
      "source": [
        "### Notes:\n",
        "* This exam consists of a **Regression** problem.  \n",
        "* The **target** feature is '**cltv**'.\n",
        "* **Random state** should be taken as **42** wherever applicable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "df = pd.read_csv(\"V1.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>area</th>\n",
              "      <th>qualification</th>\n",
              "      <th>income</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>vintage</th>\n",
              "      <th>claim_amount</th>\n",
              "      <th>num_policies</th>\n",
              "      <th>policy</th>\n",
              "      <th>type_of_policy</th>\n",
              "      <th>cltv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27529</td>\n",
              "      <td>Male</td>\n",
              "      <td>Urban</td>\n",
              "      <td>High School</td>\n",
              "      <td>42.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3849.0</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>Platinum</td>\n",
              "      <td>66816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27116</td>\n",
              "      <td>Male</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Bachelor</td>\n",
              "      <td>5.33</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3006.0</td>\n",
              "      <td>More than 1</td>\n",
              "      <td>A</td>\n",
              "      <td>Gold</td>\n",
              "      <td>67164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6499</td>\n",
              "      <td>Female</td>\n",
              "      <td>Urban</td>\n",
              "      <td>High School</td>\n",
              "      <td>2.26</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>More than 1</td>\n",
              "      <td>A</td>\n",
              "      <td>Platinum</td>\n",
              "      <td>68076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61863</td>\n",
              "      <td>Male</td>\n",
              "      <td>Rural</td>\n",
              "      <td>High School</td>\n",
              "      <td>20.29</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2844.0</td>\n",
              "      <td>More than 1</td>\n",
              "      <td>A</td>\n",
              "      <td>Platinum</td>\n",
              "      <td>63276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25045</td>\n",
              "      <td>Female</td>\n",
              "      <td>Urban</td>\n",
              "      <td>High School</td>\n",
              "      <td>5.63</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6370.0</td>\n",
              "      <td>More than 1</td>\n",
              "      <td>A</td>\n",
              "      <td>Platinum</td>\n",
              "      <td>245844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  gender   area qualification  income  marital_status  vintage  \\\n",
              "0  27529    Male  Urban   High School   42.99               0        0   \n",
              "1  27116    Male  Rural      Bachelor    5.33               1        6   \n",
              "2   6499  Female  Urban   High School    2.26               1        2   \n",
              "3  61863    Male  Rural   High School   20.29               1        8   \n",
              "4  25045  Female  Urban   High School    5.63               0        6   \n",
              "\n",
              "   claim_amount num_policies policy type_of_policy    cltv  \n",
              "0        3849.0            1      A       Platinum   66816  \n",
              "1        3006.0  More than 1      A           Gold   67164  \n",
              "2           NaN  More than 1      A       Platinum   68076  \n",
              "3        2844.0  More than 1      A       Platinum   63276  \n",
              "4        6370.0  More than 1      A       Platinum  245844  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()  # Display the first few rows of the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KdRF2l1upLN"
      },
      "source": [
        "# Metadata\n",
        "\n",
        "1. **id**-Unique identifier of a customer  \n",
        "2. **gender**-Gender of the customer   \n",
        "3. **area**-Area of the customer   \n",
        "4. **qualification**-Highest Qualification of the customer  \n",
        "5. **income**-Income earned in a year (in rupees).   \n",
        "6. **marital_status**- 0:Single, 1: Married\n",
        "7. **vintage**-No. of years since the first policy date.  \n",
        "8. **claim_amount**-Total Amount Claimed by the customer (in rupees)\n",
        "9. **num_policies**-Total no. of policies issued by the customer\n",
        "10. **policy**-Active policy of the customer\n",
        "11. **type_of_policy**-Type of active policy\n",
        "12. **cltv**- Customer life time value. It is the total amount of money a customer is expected to spend with your business, or on your products, during the lifetime of an average business relationship. **[TARGET]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWTaKRq3r2a8"
      },
      "source": [
        "### Q.2 [Marks: 2] How many total number of features (excluding target variable) are there in the dataset?\n",
        "Options\n",
        "\n",
        "A) 1000\n",
        "\n",
        "B) 11\n",
        "\n",
        "C) 12\n",
        "\n",
        "D) 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G99DfD2BK1b6"
      },
      "source": [
        "`Ans: 11 input features`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JuyUi8mw1yd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Solution\n",
        "\n",
        "df.shape[1]-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPaxHB-ar3Uo"
      },
      "source": [
        "### Q.3 [Marks: 2] What are the unique values of feature `Types of Policy` in the dataset?\n",
        "\n",
        "A) ['Bronze', 'Gold']\n",
        "\n",
        "B) ['Gold', 'Silver']\n",
        "\n",
        "C) ['Platinum', 'Gold', 'Silver', 'Bronze]\n",
        "\n",
        "D) ['Platinum', 'Gold', 'Silver']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ecgjuQHK3i_"
      },
      "source": [
        "`Ans: ['Platinum', 'Gold', 'Silver'](D)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'gender', 'area', 'qualification', 'income', 'marital_status',\n",
              "       'vintage', 'claim_amount', 'num_policies', 'policy', 'type_of_policy',\n",
              "       'cltv'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x0w30RIY1zTB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Platinum', 'Gold', 'Silver'], dtype=object)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Solution\n",
        "df['type_of_policy'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifUUdNYxsA4k"
      },
      "source": [
        "### Q.4 [Marks: 3] Which of the following columns have categorical data?[MSQ]\n",
        "\n",
        "A) income\n",
        "\n",
        "B) id\n",
        "\n",
        "C) area\n",
        "\n",
        "D) claim_amount\n",
        "\n",
        "E) qualification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIK9Gft0K6Jo"
      },
      "source": [
        "`Ans: area (C), qualification (E)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5z0FaYn11ZM"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9tuLLOqsg98"
      },
      "source": [
        "### Q.5 [Marks: 4] Plot the `heatmap` and mark the pair which has the highest positive correlation value. [MCQ]\n",
        "\n",
        "A) claim_amount & income\n",
        "\n",
        "B) income & cltv\n",
        "\n",
        "C) vintage & income.\n",
        "\n",
        "D) claim_amount & cltv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe_Yj2TZK8GD"
      },
      "source": [
        "`Ans: claim_amount and cltv (D)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmiJKp5n115D"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7cJbeFsskT1"
      },
      "source": [
        "### Q.6 [Marks: 2] Which of the following features have `missing` values?[MSQ]\n",
        "\n",
        "Options:\n",
        "\n",
        "A) gender\n",
        "\n",
        "B) area\n",
        "\n",
        "C) qualification\n",
        "\n",
        "D) income\n",
        "\n",
        "E) claim_amount\n",
        "\n",
        "F) policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viI31Tt9K-AK"
      },
      "source": [
        "`Ans: area(B), income(D), claim_amount(E), policy(F)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfNGCxr012ZP"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2i3APmsoOp"
      },
      "source": [
        "### Q.7 [Marks: 4] Break the dataset into features(`X`) and label (`y`), where the column `cltv` goes to `y` and the rest of the columns go to `X`. Enter the avg value of `cltv` column? [NAT]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tegMfcCyK_qS"
      },
      "source": [
        "`Ans: 97788.08`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXWAijQg13Pl"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdI9po-Dsybi"
      },
      "source": [
        "### Q.8 [Marks : 3] Split the dataset into training and test dataset using `train_test_split` into `70:30` ratio while keeping random_state =42. What is the shape of the training set (X_train) ? [MCQ]\n",
        "\n",
        "\n",
        "A) (4379, 11)\n",
        "\n",
        "B) (4392, 13)\n",
        "\n",
        "C) (4340, 11)\n",
        "\n",
        "D) (4379, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZPrXMpOLF7h"
      },
      "source": [
        "`Ans: (4379, 11) (A)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMlwgBFM13x2"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YC7SujBs21a"
      },
      "source": [
        "### Q.9 [Marks: 2] Drop(remove) `id` column from train and test data because it is not useful in model training. Now how many feature columns are remaining in the training dataset? [NAT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHl7GI5ALHiZ"
      },
      "source": [
        "`Ans: 10 features`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCuHUpg414P7"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pofQhio-s5gR"
      },
      "source": [
        "### Q.10 [Marks: 2] Compute and write median of the `income` column of X_train while ignoring the missing values. Replace all NaN values in the income column of X_train and X_test by the median  computed from the X_train (upto two decimal). [NAT]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX37KakpLJzp"
      },
      "source": [
        "`Ans: 7.04`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_Qi4Gvs14vf"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzYMUbQEs_Pr"
      },
      "source": [
        "### Q.11 [Marks: 2] Which is the most frequent value in the `policy` column of X_train? Replace all NaN value in `policy` column of X_train and X_test by most frequent value in X_train [MCQ]\n",
        "\n",
        "A) 'A'\n",
        "\n",
        "B) 'B'\n",
        "\n",
        "C) 'C'\n",
        "\n",
        "D) None of the above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4cYBSGvLLsL"
      },
      "source": [
        "`Ans: A`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0j3lcYq15QP"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACU-ysDBtCfm"
      },
      "source": [
        "### Q.12 [Marks: 2] Which is the most frequent value in the `area` column of X_train? Replace all NaN value in `area` column of X_train and X_test by most frequent value from X_train [MCQ]\n",
        "\n",
        "A) 'Urban'\n",
        "\n",
        "B) 'Rural'\n",
        "\n",
        "C) 'Semi-Urban'\n",
        "\n",
        "D) None of the above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etgYuDItLN85"
      },
      "source": [
        "`Ans: Urban (A)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dabdCFPF157P"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dltyhgt2tHFU"
      },
      "source": [
        "### Q.13 [Marks: 2] Replace all NaN value in claim_amount column of X_train and X_test by 0 (Zero). After Replacing NAN values from claim_amount column what is the standard deviation of claim_amount column in X_train. (correct upto two decimal places) [NAT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVdfobvtLP-I"
      },
      "source": [
        "`Ans: 3358.66`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3szfm8e-16dy"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTJ6FNLotL5L"
      },
      "source": [
        "### Q.14 [Marks: 4] Apply `MinMaxScaler` on `income` column of X_train. Compute and write median of `income` column? (correct Upto 2 decimal)[NAT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt-mhbJjLd4J"
      },
      "source": [
        "`Ans: 0.07`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO2Jmg6E17Hc"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSJWsm6XtaVR"
      },
      "source": [
        "## Apply preprocessing on features of X_train and X_test dataset.\n",
        "\n",
        "### For Categorical Features\n",
        "\n",
        "* Apply OneHotEncoding from `sklearn` library on all categorical features(object columns). Do Encoding in the order of following list\n",
        "\n",
        "  `Categorical Features = ['gender', 'area','qualification','marital_status', 'num_policies', 'policy', 'type_of_policy']`\n",
        "\n",
        "Lets call the transformed caterical feature matrix $X1$\n",
        "\n",
        "### For Numerical Features\n",
        "\n",
        "- apply MinMaxScaler and transform the dataset. Do scaling in the order of following list:\n",
        "\n",
        "  `Numerical Features =  [ 'income', 'vintage', 'claim_amount' ]`\n",
        "\n",
        "\n",
        "  - Lets call the transformed numerical feature matrix $X2$\n",
        "\n",
        "### **Concatenate**(One Hot Encoded Features, Scaled Numerical Features)\n",
        "\n",
        "After combining transformed categorical feature($X_1$) matrix and transformed numerical feature matrix ($X_2$) (side by side in that order), the output will be $X=[X_1 X_2]$\n",
        "\n",
        "### Hints\n",
        "* Apply ColumnTransformer to encode categorical columns and scaling on numerical columns with required preprocessor\n",
        "\n",
        "* Another way is to separately encode all categorical columns and scale numerical columns and do concatenate (`h-stack`) both. keep categorical columns in front of numerical while concatenating.\n",
        "\n",
        "\n",
        "* The transformed (as desribed by above steps) X_train and X_test, should be considered as X_train and X_test henceforth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbiOgCri174f"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bMmm5Nh6Ux1"
      },
      "source": [
        "## Q.15 [Marks: 10] How many features you will get after preprocessing? [MCQ]\n",
        "\n",
        "[Options]\n",
        "\n",
        "A) 13\n",
        "\n",
        "B) 20\n",
        "\n",
        "C) 25\n",
        "\n",
        "D) 01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU2Jz-I-LzL5"
      },
      "source": [
        "`Ans: 20 features (B)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3C0P-cm18XI"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx44B-1sKlCZ"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOJilIVp6Zi4"
      },
      "source": [
        "### Q.16 [Marks: 5] Apply `SequentialFeatureSelector` transformer with direction= 'forward' with `LinearRegression()` estimator and select 5 features by fitting to the X_train and y_train.\n",
        "\n",
        "  `Use cv = KFold(n_splits=5,random_state=42,shuffle=True) in SequentialFeatureSelector.`\n",
        "\n",
        "### Which of the following options represents the correct integer index of the selected features list?\n",
        "\n",
        "\n",
        "A) [ 6  9 12 13 19]\n",
        "\n",
        "B) [ 3  6  9 13 19]\n",
        "\n",
        "C) [ 8  9 12 14 19]\n",
        "\n",
        "D) [ 1  2  9 13 19]\n",
        "\n",
        "E) [ 3  7 10 13 19]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X7CKipMmcJQ"
      },
      "source": [
        "`Ans: [6 9 12 13 19](A)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHS713xj19BF"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeAqlJbI6tHl"
      },
      "source": [
        "### Q.17 [Marks: 3] Apply `LinearRegression` on the trainig set(`X_train` and `y_train`). What is the `R2 score` on the test set(`X_test` and `y_test`). ( Upto 4 digits after decimal points) [NAT]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX55TK5r_yqy"
      },
      "source": [
        "`ANS: 0.0821`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yx10SYe19jp"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvieiOk06wZO"
      },
      "source": [
        "### Q.18 [Marks: 6]Using the `LinearRegression` model, compute the `cross-validation scores` for `5 splits` on training data (X_train and y_train) using `cross_val_score`.Enter the maximum value of `ùëÖ2 score` ( Upto 4 digits after decimal points) obtained.[NAT]\n",
        "\n",
        "`Use cv = KFold(n_splits=5,random_state=42,shuffle=True) in SequentialFeatureSelector.`\n",
        "\n",
        "(**Hint**: By default cross_val_score uses LinearRegression's scoring metric, which is  ùëÖ2 score.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0GZbM4DCIBK"
      },
      "source": [
        "`Ans: 0.1816 (Range: 0.1790-0.1845)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp0BDAGU1_OR"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loebcvACChRC"
      },
      "source": [
        "### Q.19 [Marks: 5]Apply `Ridge` regression with **random_state=42** with default penalty value on training set(`X_train and y_train`) and calculate the ùëÖ2 score on test_set (`X_test and y_test`). What is the correct score ( Upto 4 digits after decimal points)? [NAT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCU0RrgcC15U"
      },
      "source": [
        "`Ans: 0.0890`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyZ8lHYp1_vU"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9QIa6EeC3Jq"
      },
      "source": [
        "### Q.20: [Marks: 6] Apply `Lasso` regression with **random_state=42** and **regularization rate=0.1** on the training data(`X_train & y_train`). Enter the value of the intercept you got correctly upto 2 digits after decimal points . [NAT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHRkUepcm0qd"
      },
      "source": [
        "`Ans: 103168.82`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa1gJeTK2AMj"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4_mFxz9C6pw"
      },
      "source": [
        "### Q.21 [Marks: 5] Fit SGDRegressor(`random_state=42`) estimator on the training data(`X_train & y_train`) and predict labels for test_data(`X_test`), lets call it as y_test_predict. The parameters are initialized with default values. Calculate and mark the correct mean_absolute_error value between y_test and y_test_predict from the given options. (Correct upto two decimals) [NAT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sZuGKgeDX8y"
      },
      "source": [
        "`Ans: 53085.49`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZrRNrBv2A19"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GES5xq7EDe44"
      },
      "source": [
        "### Q.22: [Marks: 6] Using SGDRegressor(random_state=42) as an estimator for exactly 10 iterations. Write the correct R2 score on test data  [NAT] (correct Upto 4 digits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4VnQ5YsDswP"
      },
      "source": [
        "`Ans: 0.1359`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yghT1s4f2BUC"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lNBabDYD1Fy"
      },
      "source": [
        "# (Common Instructions for Question 23 and 24)\n",
        "\n",
        "### Create a pipeline Using PolynomialFeatures as transformer and Lasso as estimator. Use GridSearchCV with this created pipeline and following hyperparameter values on training data(X_train, y_train) to fit the model .\n",
        "```\n",
        "1. Keep polynomial degree as : [1, 2]\n",
        "2. alpha value to be taken as : np.logspace(-3, 0, num=5)\n",
        "3. scoring : neg_mean_absolute_error .\n",
        "```\n",
        "(**Note**: Kindly ignore the warning.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8NB57yj2B3k"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sCZPRKVD3cq"
      },
      "source": [
        "### Q.23 [Marks: 6] Mark the best `alpha` value you got using above instructions.[MCQ]\n",
        "\n",
        "A) 0.001\n",
        "\n",
        "B) 0.00562341\n",
        "\n",
        "C) 0.03162278\n",
        "\n",
        "D) 0.17782794\n",
        "\n",
        "E) 1.00\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvznZGFlnPbU"
      },
      "source": [
        "`Ans: 1.00 (E)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1_KLP_n2Cda"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r0QpGCiD6hF"
      },
      "source": [
        "### Q.24 [Marks: 6] Enter the best polynomial degree value you got using above instructions.[NAT]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMK0xiaOnU3K"
      },
      "source": [
        "`Ans: 1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xblN4cEc2DAA"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz9LuKuID_ee"
      },
      "source": [
        "# (Common Instructions for Question 25 and 26)\n",
        "### To Reduce number of dimensions of training data with PCA. Fit the PCA model using following parameter values on training data.\n",
        "```\n",
        "n_components=5\n",
        "svd_solver='full'\n",
        "whiten=True\n",
        "random_state=42\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa_02lsA2ELf"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "todHG9ZCEDNu"
      },
      "source": [
        "### Q.25 [Marks: 5] What is the sum of `explained_variance_ratio_` ? [NAT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_Z6avGhndPT"
      },
      "source": [
        "`Ans: 0.6591`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lraY4mZh2Dk4"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjU6lefHEHHY"
      },
      "source": [
        "### Q.26 [Marks: 6] Use PCA transformed training data from earlier question and y_train to fit the `RidgeCV` estimator model having `alpha value as [0.001,0.01,0.1,1]`. Calculate the R2 score you got from the model for transformed test data(PCA transformed X_test). [NAT] (upto 4 decimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwebK1m9nlGR"
      },
      "source": [
        "`Ans: 0.0759`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXRTJQCj2Exx"
      },
      "outputs": [],
      "source": [
        "# Solution"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
